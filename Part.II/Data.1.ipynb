{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic analysis of data.\n",
    "\n",
    "In today's class we will do some basic analysis of weather data.\n",
    "\n",
    "Our source of data will be the <a href=\"http://climate.weather.gc.ca/historical_data/search_historic_data_e.html\">Canadian Weather Database</a>.\n",
    "\n",
    "Let's start by looking for the data from Victoria. \n",
    "\n",
    "Let's start by downloading the data and checking to see that we have a \"full set\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's start by loading all the weather data, storing it in a list of dictionaries. An element of \n",
    "## this list will consist of the weather file headers, turned into a dict-object.  \n",
    "\n",
    "import datetime as dt\n",
    "import os as os\n",
    "\n",
    "with open (\"eng-daily-01012017-12312017.csv\", encoding=\"utf-8\") as f:\n",
    "    content = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "﻿\"Station Name\",\"VICTORIA INTL A\"\n",
      "\n",
      "\"A\",\"Accumulated\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(content))\n",
    "print(content[0])\n",
    "print(content[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'ab', 'abc']\n",
      "ab\n",
      "{'name': 'ryan', 'age': 'old'}\n",
      "dict_keys(['name', 'age'])\n"
     ]
    }
   ],
   "source": [
    "## let's use dictionary objects\n",
    "\n",
    "L = [\"a\", \"ab\", \"abc\"] ## list object\n",
    "print(L)\n",
    "print(L[1]) ## indexed by integers 0, 1, 2, ...\n",
    "\n",
    "D = {\"name\":\"ryan\", \"age\":\"old\"}\n",
    "print(D)\n",
    "D[\"name\"]\n",
    "print(D.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Month\"\n"
     ]
    }
   ],
   "source": [
    "keys = content[25].split(\",\")\n",
    "\n",
    "fdat = []\n",
    "## let's turn the eng* file into a list of dictionary objects, one for every day.\n",
    "for i in range(26, len(content)):\n",
    "    dat = {keys[j]:content[i].split(\",\")[j] for j in range(len(keys))}\n",
    "    fdat.append(dat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "365\n",
      "{'\"Year\"': '\"2017\"', '\"Cool Deg Days Flag\"': '\"\"', '\"Data Quality\"': '\"‡\"', '\"Dir of Max Gust (10s deg)\"': '\"2\"', '\"Min Temp Flag\"': '\"\"', '\"Total Snow (cm)\"': '\"0.0\"', '\"Mean Temp Flag\"': '\"\"', '\"Max Temp (°C)\"': '\"4.9\"', '\"Spd of Max Gust (km/h)\"': '\"54\"', '\"Max Temp Flag\"': '\"\"', '\"Total Rain Flag\"': '\"\"', '\"Heat Deg Days Flag\"': '\"\"', '\"Total Rain (mm)\"': '\"1.4\"', '\"Total Precip (mm)\"': '\"1.4\"', '\"Snow on Grnd Flag\"': '\"\"', '\"Min Temp (°C)\"': '\"-1.6\"', '\"Total Snow Flag\"': '\"\"', '\"Date/Time\"': '\"2017-01-01\"', '\"Day\"': '\"01\"', '\"Spd of Max Gust Flag\"\\n': '\"\"\\n', '\"Snow on Grnd (cm)\"': '\"\"', '\"Dir of Max Gust Flag\"': '\"\"', '\"Heat Deg Days (°C)\"': '\"16.3\"', '\"Cool Deg Days (°C)\"': '\"0.0\"', '\"Mean Temp (°C)\"': '\"1.7\"', '\"Month\"': '\"01\"', '\"Total Precip Flag\"': '\"\"'}\n"
     ]
    }
   ],
   "source": [
    "print(type(fdat))\n",
    "print(len(fdat))\n",
    "print(fdat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## There will also be an additional weather-table key that will contain a list of dict objects. \n",
    "## containing the data the from a line of the file. \n",
    "\n",
    "import datetime as dt\n",
    "import os as os\n",
    "import fnmatch as fn\n",
    "from operator import itemgetter\n",
    "\n",
    "wsubdir = fn.filter(os.listdir('.'), \"w.*\")\n",
    "print(\"Weather subdirectories:\", wsubdir)\n",
    "\n",
    "## each file is of the form \"key\", \"data\" for several lines, then a blank space\n",
    "## \"Legend\" then several (ignorable) lines, then a blank space\n",
    "## \"keys\" separated by commas then\n",
    "## remaining lines are the key values for each measurement. \n",
    "\n",
    "masterList = [] ## list of weather station dict objects\n",
    "\n",
    "for wd in wsubdir:\n",
    "    files = fn.filter(os.listdir(wd), \"eng-daily*.csv\")\n",
    "    for wdf in files:\n",
    "        with open('./'+wd+'/'+wdf) as f:\n",
    "            blanks=0\n",
    "            content = f.readlines()\n",
    "            FD = dict() ## file dict head.\n",
    "            FL = [] ## file list.\n",
    "            keys = []\n",
    "            for LN in content:\n",
    "                PL = LN.replace(u'\\ufeff','').split(\",\")\n",
    "                for i in range(len(PL)): # this removes the quotes around the numbers.\n",
    "                    PL[i] = PL[i].translate({ord(c): None for c in '\"\\n'})\n",
    "                if len(PL)==1 and PL[0]=='':\n",
    "                    blanks+=1\n",
    "                    if blanks==2 and PL[0]=='':\n",
    "                        continue\n",
    "                ## if blanks==0 we need to build the main dict\n",
    "                ## if blanks==1 we ignore\n",
    "                ## if blanks==2 we build the data.\n",
    "                if blanks==0:\n",
    "                    FD[PL[0]] = PL[1]\n",
    "                    if PL[0]==\"Station Name\":\n",
    "                        FD[\"Data\"] = []\n",
    "                if blanks==2:\n",
    "                    if PL[0]==\"Date/Time\":\n",
    "                        keys = PL\n",
    "                    else:\n",
    "                        FD[\"Data\"].append( { keys[i] : PL[i] for i in range(len(keys)) } )\n",
    "            masterList.append(FD)        \n",
    "\n",
    "## make set of \"Station Name\"s. \n",
    "## use it to merge common station names into one (more useful) masterList.\n",
    "sNames = { x['Station Name'] for x in masterList}\n",
    "print(\"Station names:\", sNames)\n",
    "\n",
    "## return index of list of dict if dict keyed-element exists, -1 otherwise\n",
    "def indIfExists(LOD, keyname, value):\n",
    "    for i in range(len(LOD)):\n",
    "        if LOD[i][keyname] == value:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "## run through masterlist, if that airport exists in mList we merge, if not, we copy it over.\n",
    "mList = []\n",
    "while len(masterList)>0:\n",
    "    I = indIfExists(mList, 'Station Name', masterList[-1]['Station Name'])\n",
    "    if I<0:\n",
    "        mList.append(masterList.pop())\n",
    "    else:\n",
    "        mList[I][\"Data\"].extend(masterList.pop()[\"Data\"])\n",
    "\n",
    "## run through the weather station data, replace the date record with a datetime object\n",
    "for WS in mList:\n",
    "    badItems = set()\n",
    "    for i in range(len(WS[\"Data\"])):\n",
    "        ## Let's convert the dict from strings to appropriate datetime and float objects\n",
    "        ## dates with bad data we will flag and remove.\n",
    "        for key, value in WS[\"Data\"][i].items():\n",
    "            if key==\"Date/Time\":\n",
    "                WS[\"Data\"][i][key] = dt.datetime.strptime(value, \"%Y-%m-%d\")\n",
    "            elif key in [ 'Min Temp (°C)', 'Total Precip (mm)',  \\\n",
    "                          'Max Temp (°C)', 'Mean Temp (°C)']:\n",
    "                try:\n",
    "                    WS[\"Data\"][i][key] = float(value)\n",
    "                except:\n",
    "                    badItems.add( i )\n",
    "    #print(len(WS[\"Data\"]), end=\" \")\n",
    "    WS[\"Data\"] = [WS[\"Data\"][i] for i in range(len(WS[\"Data\"])) if i not in badItems]\n",
    "    #print(len(WS[\"Data\"]), \"\\n\")\n",
    "    WS[\"Data\"] = sorted(WS[\"Data\"], key=itemgetter(\"Date/Time\"))\n",
    "\n",
    "## now let's check for gaps.  We run through the weather station date and check the next day \n",
    "## is the previous day + one day.  If not, we start a new interval. \n",
    "print(\"Data intervals: \")\n",
    "for WS in mList:\n",
    "    print(WS['Station Name'], end=\" \")\n",
    "    ## find maximal consecutive date interval in data, then move on.\n",
    "    i0 = 0 ## start interval\n",
    "    i1 = 0 ## end interval\n",
    "    ## if date interval [i0,i1] can be expanded to be consecutive, do it.\n",
    "    ## if not, and if i1 not end of list, move to [i1+1,i1+1] and repeat\n",
    "    while i1+1 != len(WS['Data']):\n",
    "        ## if we can increment i1 and keep [i0,i1] consecutive, do it.\n",
    "        if WS['Data'][i1+1][\"Date/Time\"]-WS['Data'][i0][\"Date/Time\"] != dt.timedelta(1+i1-i0):\n",
    "            ## not consecutive. Move on.\n",
    "            print(WS['Data'][i0][\"Date/Time\"].date(), \"--\", WS['Data'][i1][\"Date/Time\"].date(), \"/ \", end='')\n",
    "            i0 = i1+1\n",
    "            i1 = i1+1\n",
    "        else:\n",
    "            i1 = i1+1\n",
    "    print(WS['Data'][i0][\"Date/Time\"].date(), \"--\", WS['Data'][i1][\"Date/Time\"].date()) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
